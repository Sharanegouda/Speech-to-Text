# -*- coding: utf-8 -*-
"""Speachtotext.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/157H2pBX7f9G3AODBHYRDHAgXgYXHVYSt
"""

# Step 1: Install dependencies
!pip install transformers torchaudio librosa soundfile -q

# Step 2: Import libraries
import torch
import torchaudio
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
import librosa
import IPython.display as ipd
from google.colab import files
import soundfile as sf

# Step 3: Upload audio file (.wav)
uploaded = files.upload()

# Get file name
filename = list(uploaded.keys())[0]

# Play uploaded audio
ipd.Audio(filename)

# Step 4: Load and resample the audio to 16kHz mono
audio_input, sample_rate = librosa.load(filename, sr=16000)

# Step 5: Load pretrained Wav2Vec2 model and processor
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")

# Preprocess the audio
inputs = processor(audio_input, sampling_rate=16000, return_tensors="pt", padding=True)

# Predict
with torch.no_grad():
    logits = model(**inputs).logits

# Get predicted IDs and decode them into text
predicted_ids = torch.argmax(logits, dim=-1)
transcription = processor.batch_decode(predicted_ids)[0]

print("üìù Transcribed Text:", transcription)

